# World Whisperer

Welcome to World Whisperer! This program helps you manage your notes on a fantasy world, vectorizes them using **local AI models**, stores them in a database, and allows you to interact with the content using **OpenRouter's unified API** for access to Claude, GPT-4, Llama, and more.

## Key Features

- üîí **Local Embeddings**: Free, fast, private vectorization using sentence-transformers
- üåê **OpenRouter Integration**: Access to multiple AI models (Claude, GPT-4, Llama, etc.)
- ‚ú® **Enhanced Generator Mode**: Smart content creation with world consistency checks
- üíæ **ChromaDB Storage**: Efficient local vector database
- üéØ **Relevance Scoring**: Automatic identification of most relevant lore

## Setup

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
cp .env.example .env
```

Edit `.env` and add your OpenRouter API key:
- Get an API key from https://openrouter.ai/keys
- Add credits (minimum $1)
- Update `openrouter_api_key` in `.env`

### 3. Prepare Your Notes
1. Rename `SampleNotes` to `Notes`
2. Create subdirectories for different content types (Characters, Locations, Items, etc.)
3. Create `.md` files inside each subfolder named after your lore items
4. Plain text is supported; markdown formatting will pass through

### 4. Initialize the Database
```bash
python main.py
```

The program will:
- Load the local embedding model (~80MB, one-time download)
- Scan your Notes directory
- Generate tags for each note using AI
- Create embeddings using the local model
- Store everything in ChromaDB

When prompted "Update ChromaDB Now?", answer `y`

## Main Menu

The main menu provides you with three modes of operation:

1. **Interactive Mode**
2. **Questions Mode**
3. **Generator Mode**

### 1. Interactive Mode

In this mode, you can interact with the model by providing the following information:

a. **Admin Command**: This is a short description to guide the response.
        Example: "You are Joe's grandfather telling stories."

b. **Context**: Provide any additional context about the prompt that isn't found in your world notes.
        Example: "Joe is a huge fan of cheese."

c. **Prompt**: Write the actual question or scenario you want ChatGPT to address.
        Example: "Tell me about the time Joe went to Italy and got a pizza."

### 2. Questions Mode

This mode allows you to ask questions about the world directly. Just type your question, and it will provide you
with an answer based on the information stored in the Pinecone database.

### 3. Generator Mode ‚ú® ENHANCED

Generator Mode enables you to create new content for your world with intelligent integration of existing lore.

**How it works:**
1. Your prompt is analyzed for relevant existing content
2. The system identifies the most relevant lore items (with scores)
3. AI generates new content that:
   - Maintains consistency with established lore
   - References existing elements appropriately
   - Matches your world's tone and style
   - Creates meaningful interconnections

**Example prompt:**
```
"Create a mysterious artifact found in the Ancient Ruins"
```

**The system will:**
- Find relevant existing lore (ruins, magic system, history)
- Show you what's most relevant (with scores)
- Generate content that fits seamlessly into your world

**Quality improvements:**
- ‚úÖ Automatic world consistency checking
- ‚úÖ Style matching with existing entries
- ‚úÖ Intelligent reference to related lore
- ‚úÖ Contradiction prevention
- ‚úÖ Relevance-aware generation

## Model Selection

The program uses **OpenRouter** to access multiple AI models. You can change the model in `.env`:

**Recommended for Generator Mode:**
```bash
openrouter_model="anthropic/claude-3.5-sonnet"  # Best quality
```

**Budget-Friendly Options:**
```bash
openrouter_model="anthropic/claude-3-haiku"     # Fast, cheap, good quality
openrouter_model="openai/gpt-3.5-turbo"         # Very cheap
```

**Other Options:**
- `openai/gpt-4-turbo` - High quality, expensive
- `meta-llama/llama-3.1-70b-instruct` - Open source

See https://openrouter.ai/models for the full list and current pricing.

## Cost Savings

**Old system (OpenAI):**
- Embeddings: $0.10+ per vectorization
- Typical session: $1-5

**New system (OpenRouter + Local):**
- Embeddings: FREE (local)
- Typical session: $0.10-1.00
- **Savings: 66-90%**

## Migration from Old Version

If you're upgrading from the OpenAI-based version, see `MIGRATION_GUIDE.md` for detailed instructions.

## Advanced Configuration

### Embedding Models

Change the local embedding model in `.env`:

```bash
# Fast, lightweight (default)
local_embed_model="all-MiniLM-L6-v2"

# Better quality, larger
local_embed_model="all-mpnet-base-v2"

# Optimized for Q&A
local_embed_model="multi-qa-mpnet-base-dot-v1"
```

### Context Settings

```bash
top_k="12"                      # Number of relevant items to retrieve
chromadb_context_limit="4000"   # Max characters in context
```

## Troubleshooting

**"No module named 'sentence_transformers'"**
```bash
pip install sentence-transformers
```

**"OPENROUTER_API_KEY not set"**
- Check your `.env` file has the correct API key
- Verify the key starts with `sk-or-v1-`

**"Embedding dimension mismatch"**
- Delete `chromadb/` directory and re-run
- This happens when switching embedding models

See `MIGRATION_GUIDE.md` for more troubleshooting tips.
